{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Uuxr7iwBnx"
      },
      "source": [
        "### 🔧 Install Required Libraries\n",
        "This cell installs the necessary packages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mWwPH4IWhZ3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63db8f67-75f8-4fc6-f28b-07609afbed1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting llama-index-retrievers-bm25\n",
            "  Downloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl.metadata (740 bytes)\n",
            "Collecting bm25s<0.3.0,>=0.2.0 (from llama-index-retrievers-bm25)\n",
            "  Downloading bm25s-0.2.13-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (0.12.46)\n",
            "Collecting pystemmer<3.0.0.0,>=2.2.0.1 (from llama-index-retrievers-bm25)\n",
            "  Downloading PyStemmer-2.2.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2.0.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.3.8)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.0.2)\n",
            "Downloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl (3.7 kB)\n",
            "Downloading bm25s-0.2.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyStemmer-2.2.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.3/669.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pystemmer, bm25s, llama-index-retrievers-bm25\n",
            "Successfully installed bm25s-0.2.13 llama-index-retrievers-bm25-0.5.2 pystemmer-2.2.0.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q llama-index-llms-google-genai llama-index pymupdf\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install nest_asyncio\n",
        "!pip install llama-index-retrievers-bm25\n",
        "!pip install -q ipywidgets\n",
        "!apt install tesseract-ocr\n",
        "!pip install pymupdf pytesseract opencv-python pillow\n",
        "!pip install sentence-transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUllT2HgwH0c"
      },
      "source": [
        "### 🧱 Environment Setup\n",
        "This cell imports all core libraries and configures the Google Gemini API key, along with some utility setup for directory and display.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyknyHvxhltC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import fitz\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "import nest_asyncio\n",
        "from google.colab import files\n",
        "from llama_index.core import Document\n",
        "from typing import List\n",
        "from llama_index.core.schema import Document, TextNode\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from llama_index.core.schema import NodeWithScore, QueryBundle\n",
        "from llama_index.core.retrievers import QueryFusionRetriever\n",
        "from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter\n",
        "from llama_index.core.text_splitter import SentenceSplitter\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "#.env\n",
        "# Set up Google API key for Gemini\n",
        "GOOGLE_API_KEY = \"AIzaSyBVA8t9cB5_Jr0MMiwLtvAVeGxxhDAnfWE\"  # Replace with your actual API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# Create a directory for our PDFs if it doesn't exist\n",
        "!mkdir -p sample_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsmgVyOHwKTt"
      },
      "source": [
        "### ⚙️ RAG Configuration Parameters\n",
        "All major parameters for chunking, retrieval, reranking, and query expansion are centralized in the `rag_config` dictionary for easier tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTERkVFep0w1"
      },
      "outputs": [],
      "source": [
        "# RAG configuration for chunking, retrieval, reranking\n",
        "#config.py\n",
        "rag_config = {\n",
        "    \"fine_chunk_size\": 256,\n",
        "    \"fine_chunk_overlap\": 20,\n",
        "    \"coarse_chunk_size\": 1024,\n",
        "    \"retrieval_top_k\": 4,\n",
        "    \"rerank_top_n\": 2,\n",
        "    \"num_query_expansions\": 3\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK9-bLN5wMi5"
      },
      "source": [
        "### 📄 Upload PDF\n",
        "This cell allows the user to upload a PDF file that will be used for building the RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA8EFEu6hlph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2ccef9af-ffcd-4b0c-e208-3fca26d67f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a PDF file to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43f3b196-76df-44a3-80b9-1092c035e379\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43f3b196-76df-44a3-80b9-1092c035e379\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving DESIGN AND SUPERVISION OF REPAIR OF HYDROPOWER PLANT.pdf to DESIGN AND SUPERVISION OF REPAIR OF HYDROPOWER PLANT.pdf\n",
            "PDF saved to sample_docs/DESIGN AND SUPERVISION OF REPAIR OF HYDROPOWER PLANT.pdf\n"
          ]
        }
      ],
      "source": [
        "def upload_pdf():\n",
        "    \"\"\"Upload a PDF file and return its path.\"\"\"\n",
        "    print(\"Please select a PDF file to upload:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.pdf'):\n",
        "            # Save to the sample_docs directory\n",
        "            pdf_path = os.path.join(\"sample_docs\", filename)\n",
        "\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(\"sample_docs\", exist_ok=True)\n",
        "\n",
        "            # Save the file\n",
        "            with open(pdf_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "\n",
        "            print(f\"PDF saved to {pdf_path}\")\n",
        "            return pdf_path\n",
        "        else:\n",
        "            print(f\"File {filename} is not a PDF. Please upload a PDF file.\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# upload your own PDF\n",
        "pdf_path = upload_pdf()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdGTO9NBTKMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📘 Load PDF and Extract Text ( PDF Parsing )\n",
        "Uses PyMuPDF to read each page of the uploaded PDF and convert it into structured LlamaIndex `Document` objects with metadata.\n"
      ],
      "metadata": {
        "id": "R-VXtzl3mA9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 📌 Convert PDF to Images for OCR\n",
        "# =======================\n",
        "def pdf_to_images(pdf_path):\n",
        "    \"\"\"\n",
        "    Convert each page of a PDF file into high-resolution images for OCR.\n",
        "    Returns a list of images, one per page.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page_num in range(len(doc)):\n",
        "            # Extract each page as a high-quality image\n",
        "            pix = doc[page_num].get_pixmap()\n",
        "            img = np.array(Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples))\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# =======================\n",
        "# 📌 Preprocess Image for OCR\n",
        "# =======================\n",
        "def preprocess_image(img, show_preview=False):\n",
        "    \"\"\"\n",
        "    Preprocess an image for OCR by enhancing contrast and sharpening.\n",
        "    Uses CLAHE for local contrast normalization and Laplacian filtering for edge enhancement.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply CLAHE to enhance local contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\n",
        "    gray = clahe.apply(gray)\n",
        "\n",
        "    # Apply a mild sharpening filter to enhance edges\n",
        "    sharpening_kernel = np.array([\n",
        "        [0, -1, 0],\n",
        "        [-1, 4.5, -1],\n",
        "        [0, -1, 0]\n",
        "    ])\n",
        "    gray = cv2.filter2D(gray, -1, sharpening_kernel)\n",
        "\n",
        "    # Resize for better OCR accuracy (Tesseract works better on larger text)\n",
        "    scale_percent = 200  # Increase image size by 200%\n",
        "    width = int(gray.shape[1] * scale_percent / 100)\n",
        "    height = int(gray.shape[0] * scale_percent / 100)\n",
        "    gray = cv2.resize(gray, (width, height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Optionally display the preprocessed image\n",
        "    if show_preview:\n",
        "        display(Image.fromarray(gray))\n",
        "\n",
        "    return gray\n",
        "\n",
        "# =======================\n",
        "# 📌 Perform OCR on Preprocessed Images\n",
        "# =======================\n",
        "def perform_ocr(images):\n",
        "    \"\"\"\n",
        "    Extracts text and bounding box data from a list of preprocessed images.\n",
        "    Returns extracted text and structured OCR data.\n",
        "    \"\"\"\n",
        "    all_text = []\n",
        "    all_ocr_data = []\n",
        "    custom_config = r'--oem 3 -l eng'  # Use Tesseract's LSTM OCR engine\n",
        "\n",
        "    for gray in images:\n",
        "        # Extract plain text\n",
        "        ocr_text = pytesseract.image_to_string(gray, config=custom_config)\n",
        "        all_text.append(ocr_text)\n",
        "\n",
        "        # Extract detailed OCR data (bounding boxes, confidence)\n",
        "        ocr_data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
        "        all_ocr_data.append(ocr_data)\n",
        "\n",
        "    return all_text, all_ocr_data\n",
        "\n",
        "# =======================\n",
        "# 📌 Bounding Box Visualization for OCR Validation\n",
        "# =======================\n",
        "def visualize_bounding_boxes(original_image, processed_image, ocr_data, confidence_threshold=30):\n",
        "    \"\"\"\n",
        "    Draws bounding boxes on the preprocessed image for verification.\n",
        "    Only boxes with confidence above the threshold are displayed.\n",
        "    \"\"\"\n",
        "    # Use a color version of the processed image for drawing\n",
        "    image_copy = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    for i in range(len(ocr_data['text'])):\n",
        "        # Extract bounding box and confidence information\n",
        "        x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n",
        "        conf = int(ocr_data['conf'][i])\n",
        "\n",
        "        # Draw only high-confidence boxes\n",
        "        if conf > confidence_threshold:\n",
        "            image_copy = cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            text = ocr_data['text'][i].strip()\n",
        "            if text:\n",
        "                # Overlay the recognized text near the bounding box\n",
        "                cv2.putText(image_copy, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    plt.figure(figsize=(15, 20))\n",
        "    plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# =======================\n",
        "# 📌 Document Type Detection\n",
        "# =======================\n",
        "def is_scanned_pdf(pdf_path, text_threshold=100):\n",
        "    \"\"\"\n",
        "    Detects if a PDF is scanned or well-structured.\n",
        "    Returns True if the PDF is likely scanned (low text content), False otherwise.\n",
        "    \"\"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        total_text = \"\".join([page.get_text() for page in doc])\n",
        "\n",
        "    # Consider it scanned if the total extracted text is below the threshold\n",
        "    return len(total_text.strip()) < text_threshold\n",
        "\n",
        "# =======================\n",
        "# 📌 Main Processing Logic (Optimized)\n",
        "# =======================\n",
        "def process_and_index_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Process a scanned or well-structured PDF and create a vector index with improved handling for structured PDFs.\n",
        "    \"\"\"\n",
        "    # Check if the document is scanned\n",
        "    is_scanned = is_scanned_pdf(pdf_path)\n",
        "\n",
        "    # Extract text based on document type\n",
        "    if is_scanned:\n",
        "        print(\"📝 Document Type: Scanned (OCR Required)\")\n",
        "        images = pdf_to_images(pdf_path)\n",
        "        preprocessed_images = [preprocess_image(img) for img in images]\n",
        "        ocr_texts, ocr_datasets = perform_ocr(preprocessed_images)\n",
        "        documents = [Document(text=text) for text in ocr_texts]\n",
        "    else:\n",
        "        print(\"✅ Document Type: Well-Structured (No OCR Needed)\")\n",
        "        documents = []\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for i, page in enumerate(doc):\n",
        "                # Extract raw text from each page\n",
        "                text = page.get_text()\n",
        "\n",
        "                # Preserve critical newlines for logical chunking\n",
        "                text = \"\\n\".join([line.strip() for line in text.splitlines() if line.strip()])\n",
        "\n",
        "                # Create Document object with metadata\n",
        "                documents.append(Document(\n",
        "                    text=text,\n",
        "                    metadata={\n",
        "                        \"file_name\": os.path.basename(pdf_path),\n",
        "                        \"page_number\": i + 1,\n",
        "                        \"total_pages\": len(doc)\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "    # Create vector index\n",
        "    all_nodes = multi_granularity_chunking(documents, pdf_path=pdf_path)\n",
        "    vector_index = VectorStoreIndex(all_nodes)\n",
        "    print(f\"✅ Indexed {len(all_nodes)} multi-granularity chunks\")\n",
        "\n",
        "    return vector_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fCnNYM_rl5-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cpiw3gawXoQ"
      },
      "source": [
        "### 🧩 Multi-Granularity Chunking\n",
        "Splits each document into both fine-grained (sentence-level) and coarse-grained (section/page-level) chunks for better retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKaRrzKNmb0N"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# 📌 Multi-Granularity Chunking (Optimized for Structured and Scanned PDFs)\n",
        "# =======================\n",
        "\n",
        "def multi_granularity_chunking(documents, pdf_path, text_threshold=100):\n",
        "    \"\"\"\n",
        "    Generate fine, coarse, and logical chunks with separate strategies for structured and scanned PDFs.\n",
        "    - Retains precise section titles for structured PDFs.\n",
        "    - Simplifies chunking for scanned PDFs to reduce noise.\n",
        "    \"\"\"\n",
        "    # Check if the document is scanned\n",
        "    is_scanned = is_scanned_pdf(pdf_path, text_threshold=text_threshold)\n",
        "\n",
        "    fine_nodes = []\n",
        "    coarse_nodes = []\n",
        "    logical_nodes = []\n",
        "\n",
        "    # Fine-grained chunking (sentence-level)\n",
        "    sentence_splitter = SentenceSplitter(\n",
        "        chunk_size=rag_config[\"fine_chunk_size\"],\n",
        "        chunk_overlap=rag_config[\"fine_chunk_overlap\"]\n",
        "    )\n",
        "    for i, doc in enumerate(documents):\n",
        "        nodes = sentence_splitter.get_nodes_from_documents([doc])\n",
        "        for node in nodes:\n",
        "            node.metadata[\"chunk_type\"] = \"fine\"\n",
        "            node.metadata[\"page_number\"] = i + 1\n",
        "        fine_nodes.extend(nodes)\n",
        "\n",
        "    # Coarse-grained chunking (paragraph-level)\n",
        "    coarse_parser = SimpleNodeParser.from_defaults(\n",
        "        chunk_size=rag_config[\"coarse_chunk_size\"]\n",
        "    )\n",
        "    for i, doc in enumerate(documents):\n",
        "        nodes = coarse_parser.get_nodes_from_documents([doc])\n",
        "        for node in nodes:\n",
        "            node.metadata[\"chunk_type\"] = \"coarse\"\n",
        "            node.metadata[\"page_number\"] = i + 1\n",
        "        coarse_nodes.extend(nodes)\n",
        "\n",
        "    # Logical chunking (Structured PDFs)\n",
        "    if not is_scanned:\n",
        "        for doc in documents:\n",
        "            lines = doc.text.split(\"\\n\")\n",
        "            current_chunk = []\n",
        "            collecting = False\n",
        "            section_title = None\n",
        "\n",
        "            for line in lines:\n",
        "                line_strip = line.strip()\n",
        "\n",
        "                # Detect known section headers\n",
        "                if any(anchor in line_strip.upper() for anchor in [\n",
        "                    \"TOTAL ESTIMATED MONTHLY PAYMENT\",\n",
        "                    \"FEES WORKSHEET\",\n",
        "                    \"ORIGINATION CHARGES\",\n",
        "                    \"OTHER CHARGES\"\n",
        "                ]):\n",
        "                    if current_chunk:\n",
        "                        chunk_text = \"\\n\".join(current_chunk)\n",
        "                        logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "                        current_chunk = []\n",
        "\n",
        "                    collecting = True\n",
        "                    section_title = line_strip\n",
        "                    current_chunk = [line_strip]\n",
        "                    continue\n",
        "\n",
        "                if collecting:\n",
        "                    if line_strip == \"\" and current_chunk:\n",
        "                        chunk_text = \"\\n\".join(current_chunk)\n",
        "                        logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "                        current_chunk = []\n",
        "                        collecting = False\n",
        "                    else:\n",
        "                        current_chunk.append(line_strip)\n",
        "\n",
        "            # Add remaining chunk\n",
        "            if current_chunk:\n",
        "                chunk_text = \"\\n\".join(current_chunk)\n",
        "                logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "\n",
        "    # Logical chunking (Scanned PDFs)\n",
        "    else:\n",
        "        for doc in documents:\n",
        "            lines = doc.text.split(\"\\n\")\n",
        "            current_chunk = []\n",
        "            for line in lines:\n",
        "                line_strip = line.strip()\n",
        "                if line_strip:\n",
        "                    current_chunk.append(line_strip)\n",
        "            if current_chunk:\n",
        "                logical_nodes.append(TextNode(\n",
        "                    text=\"\\n\".join(current_chunk),\n",
        "                    metadata={\"chunk_type\": \"logical\"}\n",
        "                ))\n",
        "\n",
        "    # Print summary for verification\n",
        "    print(f\"✅ Final Chunk Counts - Fine: {len(fine_nodes)}, Coarse: {len(coarse_nodes)}, Logical: {len(logical_nodes)}\")\n",
        "\n",
        "    return fine_nodes + coarse_nodes + logical_nodes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P27jpGZ1waOQ"
      },
      "source": [
        "### 📚 Embedding and Index Construction\n",
        "Initializes the Gemini LLM and HuggingFace embedding model, then builds a vector index from multi-granularity chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPOWFNl-hlhX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Set up the custom prompt for the Gemini LLM\n",
        "custom_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are a highly skilled legal assistant specializing in analyzing legal documents. \"\n",
        "        \"Your task is to accurately extract and reason over the content retrieved from these documents. \"\n",
        "        \"Always rely on the retrieved context only — do not assume or hallucinate any values or terms.\\n\\n\"\n",
        "        \"When answering:\\n\"\n",
        "        \"- Be precise with all numerical values, dates, and percentages.\\n\"\n",
        "        \"- When totals are requested, check if they need to be calculated from individual components.\\n\"\n",
        "        \"- If a query implies composition or reasoning (e.g., total payment, remaining balance), compute carefully and explain briefly if needed.\\n\"\n",
        "        \"- If the information is not in the retrieved content, respond clearly that it was not found.\\n\"\n",
        "        \"- Use law-specific terminology appropriately and avoid ambiguity.\\n\\n\"\n",
        "        \"You are being used in a legal setting where accuracy and clarity are critical.\"\n",
        "    )),\n",
        "    (\"user\", \"{query_str}\")\n",
        "])\n",
        "\n",
        "# Initialize the Gemini LLM\n",
        "llm = GoogleGenAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    prompt=custom_prompt,\n",
        "    max_output_tokens=1024  # Adjust based on your use case\n",
        ")\n",
        "\n",
        "# Initialize the HuggingFace embedding model\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")  # or \"intfloat/e5-base-v2\"\n",
        "Settings.embed_model = embed_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRnAO5IcwjHx"
      },
      "source": [
        "### 🚀 Index the Uploaded PDF\n",
        "Calls the full document processing and indexing function to prepare for RAG-based querying.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQPaeltMhlet",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e539d7-e106-4325-f56f-36e553da7dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Document Type: Well-Structured (No OCR Needed)\n",
            "✅ Final Chunk Counts - Fine: 21, Coarse: 8, Logical: 0\n",
            "✅ Indexed 29 multi-granularity chunks\n"
          ]
        }
      ],
      "source": [
        "# =======================\n",
        "# 📌 Run the Indexing\n",
        "# =======================\n",
        "index = process_and_index_pdf(pdf_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JT8UGiiw36W"
      },
      "source": [
        "### 🧠 Full RAG Pipeline Builder\n",
        "Constructs the complete Retrieval-Augmented Generation engine with hybrid retrieval (semantic + keyword), query expansion, and reranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLAy6xLahlUS",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "53cf7b6c-5559-4743-f7ea-dc6d2c111a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index contains 29 nodes, using top_k=4\n",
            "✅ Hybrid RAG Pipeline built successfully with 29 nodes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Stage  Rank     Score  \\\n",
              "0  Original Retrieval     1 -8.925238   \n",
              "1  Original Retrieval     2  0.091755   \n",
              "2  Original Retrieval     3 -5.441075   \n",
              "3  Original Retrieval     4 -5.808973   \n",
              "4     After Reranking     1  0.091755   \n",
              "5     After Reranking     2 -5.441075   \n",
              "\n",
              "                                             Content  Page  \n",
              "0  X.\\nMATERIALS, COST, AND DISBURSEMENTS\\nServic...     3  \n",
              "1  acts which may be due to unforeseen events or ...     6  \n",
              "2  XIX.\\nINDEMNITY\\nExcept for any payment in set...     5  \n",
              "3  acts which may be due to unforeseen events or ...     6  \n",
              "4  acts which may be due to unforeseen events or ...     6  \n",
              "5  XIX.\\nINDEMNITY\\nExcept for any payment in set...     5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ba6b8f-1993-4e27-a222-c1845cd4b66e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stage</th>\n",
              "      <th>Rank</th>\n",
              "      <th>Score</th>\n",
              "      <th>Content</th>\n",
              "      <th>Page</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>1</td>\n",
              "      <td>-8.925238</td>\n",
              "      <td>X.\\nMATERIALS, COST, AND DISBURSEMENTS\\nServic...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>2</td>\n",
              "      <td>0.091755</td>\n",
              "      <td>acts which may be due to unforeseen events or ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>3</td>\n",
              "      <td>-5.441075</td>\n",
              "      <td>XIX.\\nINDEMNITY\\nExcept for any payment in set...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>4</td>\n",
              "      <td>-5.808973</td>\n",
              "      <td>acts which may be due to unforeseen events or ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After Reranking</td>\n",
              "      <td>1</td>\n",
              "      <td>0.091755</td>\n",
              "      <td>acts which may be due to unforeseen events or ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>After Reranking</td>\n",
              "      <td>2</td>\n",
              "      <td>-5.441075</td>\n",
              "      <td>XIX.\\nINDEMNITY\\nExcept for any payment in set...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ba6b8f-1993-4e27-a222-c1845cd4b66e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22ba6b8f-1993-4e27-a222-c1845cd4b66e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22ba6b8f-1993-4e27-a222-c1845cd4b66e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b1760377-6219-4bef-8efc-6aa6ef0d6039\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1760377-6219-4bef-8efc-6aa6ef0d6039')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b1760377-6219-4bef-8efc-6aa6ef0d6039 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"run_query_with_reranking(\\\"What is the applicable laws?\\\", top_k=4)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"After Reranking\",\n          \"Original Retrieval\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.09175454080104828,\n          -5.80897331237793\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"X.\\nMATERIALS, COST, AND DISBURSEMENTS\\nService Provider is permitted to change for all reasonable and necessary costs and\\nexpenses incurred in performi...\",\n          \"acts which may be due to unforeseen events or though foreseen could not be reasonably\\navoided. However, liability will apply to party who failed to co...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_rag_pipeline(index):\n",
        "    \"\"\"Build a RAG pipeline with hybrid retrieval, query expansion, and reranking.\"\"\"\n",
        "\n",
        "    # Get all nodes from the index's docstore\n",
        "    nodes = list(index.docstore.docs.values())\n",
        "    num_nodes = len(nodes)\n",
        "\n",
        "    # Set top_k based on configuration\n",
        "    safe_top_k = min(rag_config[\"retrieval_top_k\"], max(1, num_nodes))\n",
        "    print(f\"Index contains {num_nodes} nodes, using top_k={safe_top_k}\")\n",
        "\n",
        "    # Step 1: Define Filters for Each Retrieval Method\n",
        "    filter_by_fine_type = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"fine\")])\n",
        "    filter_by_coarse_type = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"coarse\")])\n",
        "    filter_by_page_level = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"page\")])\n",
        "\n",
        "    # Step 2: Create Individual Retrievers\n",
        "    vector_retriever = index.as_retriever(similarity_top_k=safe_top_k, filters=filter_by_fine_type)\n",
        "    bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=safe_top_k)\n",
        "    page_retriever = index.as_retriever(similarity_top_k=safe_top_k, filters=filter_by_page_level)\n",
        "\n",
        "    # Step 3: Hybrid Retriever for Combining Methods\n",
        "    class HybridRetriever(BaseRetriever):\n",
        "        def __init__(self, vector_retriever, bm25_retriever, page_retriever, top_k):\n",
        "            self.vector_retriever = vector_retriever\n",
        "            self.bm25_retriever = bm25_retriever\n",
        "            self.page_retriever = page_retriever\n",
        "            self.top_k = top_k\n",
        "            super().__init__()\n",
        "\n",
        "        def _retrieve(self, query_bundle, **kwargs):\n",
        "            vector_nodes = self.vector_retriever.retrieve(query_bundle)\n",
        "            bm25_nodes = self.bm25_retriever.retrieve(query_bundle)\n",
        "            page_nodes = self.page_retriever.retrieve(query_bundle)\n",
        "\n",
        "            # Combine all retrieved nodes\n",
        "            all_nodes = list(vector_nodes) + list(bm25_nodes) + list(page_nodes)\n",
        "\n",
        "            # Remove duplicates by node_id\n",
        "            unique_nodes = {}\n",
        "            for node in all_nodes:\n",
        "                if node.node_id not in unique_nodes:\n",
        "                    unique_nodes[node.node_id] = node\n",
        "\n",
        "            # Sort nodes by score, highest first\n",
        "            sorted_nodes = sorted(\n",
        "                unique_nodes.values(),\n",
        "                key=lambda x: x.score if hasattr(x, \"score\") and x.score else 0.0,\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            # Return top_k results\n",
        "            return sorted_nodes[:self.top_k]\n",
        "\n",
        "    # Initialize Hybrid Retriever\n",
        "    hybrid_retriever = HybridRetriever(\n",
        "        vector_retriever=vector_retriever,\n",
        "        bm25_retriever=bm25_retriever,\n",
        "        page_retriever=page_retriever,\n",
        "        top_k=safe_top_k\n",
        "    )\n",
        "\n",
        "    # Step 4: Reranker (Optional)\n",
        "    node_postprocessors = []\n",
        "    if num_nodes > 1:\n",
        "        reranker = SentenceTransformerRerank(\n",
        "            model=\"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
        "            top_n=min(rag_config[\"rerank_top_n\"], num_nodes)\n",
        "        )\n",
        "        node_postprocessors.append(reranker)\n",
        "\n",
        "    # Step 5: Query Expansion with Fusion Retriever\n",
        "    fusion_retriever = QueryFusionRetriever(\n",
        "        retrievers=[hybrid_retriever],\n",
        "        llm=llm,\n",
        "        num_queries=rag_config[\"num_query_expansions\"],\n",
        "        similarity_top_k=safe_top_k,\n",
        "        mode=\"reciprocal_rerank\"\n",
        "    )\n",
        "\n",
        "    # Step 6: Final Query Engine\n",
        "    query_engine = RetrieverQueryEngine.from_args(\n",
        "        retriever=fusion_retriever,\n",
        "        llm=llm,\n",
        "        node_postprocessors=node_postprocessors\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Hybrid RAG Pipeline built successfully with {num_nodes} nodes.\")\n",
        "\n",
        "    def run_query_with_reranking(query_text, top_k=4):\n",
        "        query_bundle = QueryBundle(query_str=query_text)\n",
        "        nodes = hybrid_retriever._retrieve(query_bundle)\n",
        "        reranked_nodes = reranker.postprocess_nodes(nodes, query_str=query_text) if reranker else nodes\n",
        "\n",
        "        # Prepare DataFrame for comparison\n",
        "        results = []\n",
        "\n",
        "        # Combined Results for Comparison\n",
        "        for i, node in enumerate(nodes):\n",
        "            results.append({\n",
        "                \"Stage\": \"Original Retrieval\",\n",
        "                \"Rank\": i + 1,\n",
        "                \"Score\": node.score,\n",
        "                \"Content\": node.get_text()[:150] + \"...\",\n",
        "                \"Page\": node.metadata.get(\"page_number\", \"Unknown\")\n",
        "            })\n",
        "\n",
        "        for i, node in enumerate(reranked_nodes):\n",
        "            results.append({\n",
        "                \"Stage\": \"After Reranking\",\n",
        "                \"Rank\": i + 1,\n",
        "                \"Score\": node.score,\n",
        "                \"Content\": node.get_text()[:150] + \"...\",\n",
        "                \"Page\": node.metadata.get(\"page_number\", \"Unknown\")\n",
        "            })\n",
        "\n",
        "        # Display the results in a clean table\n",
        "        results_df = pd.DataFrame(results)\n",
        "        display(results_df)\n",
        "\n",
        "    return query_engine, run_query_with_reranking\n",
        "\n",
        "# Rebuild the RAG pipeline\n",
        "rag_engine, run_query_with_reranking = build_rag_pipeline(index)\n",
        "\n",
        "# Example usage of the integrated reranking demonstration\n",
        "run_query_with_reranking(\"What is the applicable laws?\", top_k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHXrXah0xI3Z"
      },
      "source": [
        "### 🔍 Run a Sample Query\n",
        "This cell queries the final RAG engine to answer a question using the processed PDF content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gV3gPW2j2zF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489,
          "referenced_widgets": [
            "074ed3f098e143b781f02a98ac727522",
            "8f50b3c5667a413baf1e34e7f3bef0b4",
            "34e3410d81b747679b3ced5662387cdb",
            "ecf52297fcf84d05a94b8d84936b6a6d",
            "4253af2bb8ce4c1083c04e71e63ce7b6",
            "6a6447b72f024b128ff6abffc5a78a1d",
            "a85c9935b4cd4ad5b3857f2ac449e9a5",
            "397450f423294be0abfdec964539043a",
            "693c044c73aa49b4ade21fd2220cebed",
            "001cb2c00a4048d69f8c01b3398811a6",
            "7cf2ae52aa3f453aadc31c9ebb244a10",
            "c2a52f2521b7465c8580aafcf0f537db",
            "ff6f97e0ac5341d6922d773c6f6730d7",
            "a03fef8be7554ec5a7d5263e3275b9ce",
            "19da7cce19c644288b99fe815c0a746d"
          ]
        },
        "outputId": "eaddf79e-3487-45e0-c7ce-4e450e924717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Document Type: Well-Structured (No OCR Needed)\n",
            "✅ Final Chunk Counts - Fine: 21, Coarse: 8, Logical: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Indexed 29 multi-granularity chunks\n",
            "Index contains 29 nodes, using top_k=4\n",
            "✅ Hybrid RAG Pipeline built successfully with 29 nodes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(ToggleButtons(description='Action:', options=('Extract Only', 'Save Renamed Copy'), value='Extr…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074ed3f098e143b781f02a98ac727522"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import shutil\n",
        "import re\n",
        "import os\n",
        "\n",
        "# 📁 Confirmation dropdown before saving\n",
        "save_choice = widgets.ToggleButtons(\n",
        "    options=[\"Extract Only\", \"Save Renamed Copy\"],\n",
        "    description=\"Action:\",\n",
        "    button_style=''\n",
        ")\n",
        "\n",
        "# 📦 Output for response or message\n",
        "preprocess_output = widgets.Output()\n",
        "\n",
        "def handle_save_decision(change):\n",
        "    with preprocess_output:\n",
        "        clear_output()\n",
        "\n",
        "        if change.new == \"Save Renamed Copy\":\n",
        "            try:\n",
        "                # 🔍 Ask what the document is about (get structured title)\n",
        "                title_response = rag_engine.query(\n",
        "                    \"Generate an appropriate title for the document, mentioning the main person involved, date indicated in the document, what type of document it is (e.g. power of attorney, turnover of will, restraining order, etc). Format it like: YYYYMMDD_Name_TypeOfDocument.\"\n",
        "                ).response\n",
        "\n",
        "                # 🧹 Clean title for filename\n",
        "                safe_title = re.sub(r'[^a-zA-Z0-9_-]', '', title_response.strip().replace(\" \", \"_\"))\n",
        "                safe_title = safe_title[:80]  # Limit filename length\n",
        "\n",
        "                # 🗂 Decide on folder based on doc type (assumed last part after last underscore)\n",
        "                doc_type = safe_title.split(\"_\")[-1]\n",
        "                destination_folder = os.path.join(\"sorted_docs\", doc_type)\n",
        "\n",
        "                # 📁 Ensure directory exists\n",
        "                os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "                # 📝 New path\n",
        "                new_pdf_path = os.path.join(destination_folder, f\"{safe_title}.pdf\")\n",
        "\n",
        "                # 📂 Copy PDF\n",
        "                shutil.copy(pdf_path, new_pdf_path)\n",
        "\n",
        "                print(f\"✅ File saved as: {new_pdf_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Could not save renamed file: {e}\")\n",
        "\n",
        "        else:\n",
        "            print(\"📄 Proceeding without saving a renamed copy.\")\n",
        "\n",
        "# Run index creation and pipeline build\n",
        "index = process_and_index_pdf(pdf_path)\n",
        "rag_engine, run_query_with_reranking = build_rag_pipeline(index)\n",
        "\n",
        "# Link save decision to handler\n",
        "save_choice.observe(handle_save_decision, names='value')\n",
        "\n",
        "\n",
        "# 📝 Multiline text input\n",
        "query_input = widgets.Textarea(\n",
        "    placeholder='Type or select a query...',\n",
        "    description='Query:',\n",
        "    layout=widgets.Layout(width='90%', height='120px')\n",
        ")\n",
        "\n",
        "# 🔘 Submit button\n",
        "submit_button = widgets.Button(\n",
        "    description='Submit',\n",
        "    button_style='success',\n",
        "    tooltip='Submit your query',\n",
        "    icon='search'\n",
        ")\n",
        "\n",
        "# 📦 Output box\n",
        "output_box = widgets.Output()\n",
        "\n",
        "# 🧠 Define query execution function\n",
        "def run_query(query_text):\n",
        "    try:\n",
        "        cleaned_query = query_text.strip()\n",
        "        response = rag_engine.query(cleaned_query).response\n",
        "\n",
        "        formatted_response = f\"\"\"\n",
        "        <div style=\"\n",
        "            background-color: #f9f9f9;\n",
        "            border-left: 6px solid #007bff;\n",
        "            padding: 15px;\n",
        "            margin-bottom: 15px;\n",
        "            border-radius: 8px;\n",
        "            font-family: Arial, sans-serif;\n",
        "            color: #000000;\n",
        "        \">\n",
        "        <h3>📝 Query:</h3>\n",
        "        <p><strong>{cleaned_query}</strong></p>\n",
        "        <hr>\n",
        "        <h3>📄 Response:</h3>\n",
        "        <p>{response}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        with output_box:\n",
        "            clear_output()\n",
        "            display(HTML(formatted_response))\n",
        "\n",
        "    except Exception as e:\n",
        "        with output_box:\n",
        "            clear_output()\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style=\"\n",
        "                background-color: #f8d7da;\n",
        "                border-left: 6px solid #dc3545;\n",
        "                padding: 15px;\n",
        "                margin-bottom: 15px;\n",
        "                border-radius: 8px;\n",
        "                font-family: Arial, sans-serif;\n",
        "                color: #000000;\n",
        "            \">\n",
        "            <h3>❌ Error:</h3>\n",
        "            <p>{str(e)}</p>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "submit_button.on_click(lambda b: run_query(query_input.value.strip()))\n",
        "\n",
        "# 🎯 Display UI\n",
        "display(widgets.VBox([\n",
        "    save_choice,\n",
        "    preprocess_output,\n",
        "    query_input,\n",
        "    submit_button,\n",
        "    output_box\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctMyXE5I2ATs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "074ed3f098e143b781f02a98ac727522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f50b3c5667a413baf1e34e7f3bef0b4",
              "IPY_MODEL_34e3410d81b747679b3ced5662387cdb",
              "IPY_MODEL_ecf52297fcf84d05a94b8d84936b6a6d",
              "IPY_MODEL_4253af2bb8ce4c1083c04e71e63ce7b6",
              "IPY_MODEL_6a6447b72f024b128ff6abffc5a78a1d"
            ],
            "layout": "IPY_MODEL_a85c9935b4cd4ad5b3857f2ac449e9a5"
          }
        },
        "8f50b3c5667a413baf1e34e7f3bef0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "Extract Only",
              "Save Renamed Copy"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "Action:",
            "description_tooltip": null,
            "disabled": false,
            "icons": [],
            "index": 0,
            "layout": "IPY_MODEL_397450f423294be0abfdec964539043a",
            "style": "IPY_MODEL_693c044c73aa49b4ade21fd2220cebed",
            "tooltips": []
          }
        },
        "34e3410d81b747679b3ced5662387cdb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a03fef8be7554ec5a7d5263e3275b9ce",
            "msg_id": "",
            "outputs": []
          }
        },
        "ecf52297fcf84d05a94b8d84936b6a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Query:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_001cb2c00a4048d69f8c01b3398811a6",
            "placeholder": "Type or select a query...",
            "rows": null,
            "style": "IPY_MODEL_7cf2ae52aa3f453aadc31c9ebb244a10",
            "value": "how much is the client's service fees?"
          }
        },
        "4253af2bb8ce4c1083c04e71e63ce7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Submit",
            "disabled": false,
            "icon": "search",
            "layout": "IPY_MODEL_c2a52f2521b7465c8580aafcf0f537db",
            "style": "IPY_MODEL_ff6f97e0ac5341d6922d773c6f6730d7",
            "tooltip": "Submit your query"
          }
        },
        "6a6447b72f024b128ff6abffc5a78a1d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_19da7cce19c644288b99fe815c0a746d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "\n        <div style=\"\n            background-color: #f9f9f9;\n            border-left: 6px solid #007bff;\n            padding: 15px;\n            margin-bottom: 15px;\n            border-radius: 8px;\n            font-family: Arial, sans-serif;\n            color: #000000;\n        \">\n        <h3>📝 Query:</h3>\n        <p><strong>how much is the client's service fees?</strong></p>\n        <hr>\n        <h3>📄 Response:</h3>\n        <p>The client's service fees are a fixed fee of Php600,000.00, with a progressive service fee applied thereafter with 10% retentions.\n</p>\n        </div>\n        "
                },
                "metadata": {}
              }
            ]
          }
        },
        "a85c9935b4cd4ad5b3857f2ac449e9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397450f423294be0abfdec964539043a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693c044c73aa49b4ade21fd2220cebed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        },
        "001cb2c00a4048d69f8c01b3398811a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "120px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "7cf2ae52aa3f453aadc31c9ebb244a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2a52f2521b7465c8580aafcf0f537db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6f97e0ac5341d6922d773c6f6730d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a03fef8be7554ec5a7d5263e3275b9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19da7cce19c644288b99fe815c0a746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}